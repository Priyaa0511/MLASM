{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "VRa_egJYnad4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import libraries"
      ],
      "metadata": {
        "id": "YQUldJVtnc8k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "946ocF3bngYZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import lightgbm as lgb\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import xgboost as xgb"
      ],
      "metadata": {
        "id": "FyMQjlaYnz2D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data pre-processing"
      ],
      "metadata": {
        "id": "-HSNjntpn1wL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data=pd.read_csv('drive/MyDrive/Colab Notebooks/anticancertrain.csv')"
      ],
      "metadata": {
        "id": "YsyHDKqFod-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.shape"
      ],
      "metadata": {
        "id": "ZBNc8p15nmT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.dtypes.value_counts()"
      ],
      "metadata": {
        "id": "xnjhl1imo-5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Below code gives percentage of null in every column\n",
        "null_percentage = train_data.isnull().sum()/train_data.shape[0]*100\n",
        "\n",
        "# Below code gives list of columns having more than 60% null\n",
        "col_to_drop = null_percentage[null_percentage>60].keys()\n",
        "\n",
        "train_data = train_data.drop(col_to_drop, axis=1)"
      ],
      "metadata": {
        "id": "nVn7W2xXpCjd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.shape"
      ],
      "metadata": {
        "id": "NyEp-Rb_pFZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.isna().sum().sort_values(ascending=False).head(10)"
      ],
      "metadata": {
        "id": "C_CvELoLpI7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get the columns with null values\n",
        "null_cols = train_data.columns[train_data.isnull().any()]\n",
        "\n",
        "# get the count of each data type for columns with null values\n",
        "dtype_counts = train_data[null_cols].dtypes.value_counts()\n",
        "dtype_counts"
      ],
      "metadata": {
        "id": "I5J4Xt8-pLzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get the mean of the columns with float data type\n",
        "mean_values = train_data.select_dtypes(include=['float']).mean()\n",
        "\n",
        "# replace missing values with mean for float columns\n",
        "train_data[train_data.select_dtypes(include=['float']).columns] = train_data.select_dtypes(include=['float']).fillna(mean_values)"
      ],
      "metadata": {
        "id": "Y4r6p7gapOeJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data=train_data.drop('name',axis=1)"
      ],
      "metadata": {
        "id": "xgD5ZEiUpQ02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "X as the feature matrix, including all descriptors, and y as the response variable"
      ],
      "metadata": {
        "id": "jcWdLuppu98w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X=train_data.drop('cls',axis=1)\n",
        "y=train_data['cls']"
      ],
      "metadata": {
        "id": "BYcoGxvpuwij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n6e3L-CKKgbW"
      },
      "outputs": [],
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X = imputer.fit_transform(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature selection"
      ],
      "metadata": {
        "id": "it61YdvRplDM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import VarianceThreshold\n",
        "\n",
        "# Define the threshold value\n",
        "threshold_value = 0.70  # Adjust as needed\n",
        "\n",
        "# Initialize the VarianceThreshold selector\n",
        "selector = VarianceThreshold(threshold=threshold_value)\n",
        "\n",
        "# Apply the selector to the original DataFrame\n",
        "X_selected = selector.fit_transform(X)\n",
        "\n",
        "# Get the indices of the selected features\n",
        "selected_indices = selector.get_support(indices=True)\n",
        "\n",
        "# Get the selected feature names\n",
        "selected_features = X.columns[selected_indices]\n",
        "\n",
        "# Create the final DataFrame with selected features\n",
        "X = X[selected_features]"
      ],
      "metadata": {
        "id": "u8mykjmWpnPR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cross validation and model generation and ROC curve"
      ],
      "metadata": {
        "id": "meW2RZwnpdb7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import matthews_corrcoef, confusion_matrix, roc_curve, roc_auc_score, accuracy_score\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Create a dictionary of models\n",
        "models = {\n",
        "    'Random Forest': RandomForestClassifier(n_estimators=300,random_state=42,max_depth=10),\n",
        "    'LightGBM': lgb.LGBMClassifier(force_col_wise=True, n_estimators=100, max_depth=10, num_leaves=50, learning_rate=0.2),\n",
        "    'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=5),\n",
        "    'Decision Tree': DecisionTreeClassifier(criterion='entropy', max_depth=10, min_samples_split=10, min_samples_leaf=2, random_state=42),\n",
        "    'XGBoost': xgb.XGBClassifier(learning_rate=0.1, max_depth=3, reg_lambda=0.5, n_estimators=100)\n",
        "}\n",
        "\n",
        "# Create subplots\n",
        "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# Initialize the result dictionaries\n",
        "train_results = {}\n",
        "test_results = {}\n",
        "\n",
        "# Loop through each model\n",
        "for model_name, model in models.items():\n",
        "    # Fit the model\n",
        "    model.fit(X, y)\n",
        "\n",
        "    # Perform cross-validation and get predicted probabilities for training set\n",
        "    y_probas_train = cross_val_predict(model, X, y, cv=10, method=\"predict_proba\")[:, 1]\n",
        "\n",
        "    # Calculate AUC for training set\n",
        "    fpr_train, tpr_train, _ = roc_curve(y, y_probas_train)\n",
        "    auc_train = roc_auc_score(y, y_probas_train)\n",
        "\n",
        "    # Calculate Matthews Correlation Coefficient\n",
        "    mcc = matthews_corrcoef(y, (y_probas_train > 0.5).astype(int))\n",
        "\n",
        "    # Calculate Sensitivity and Specificity\n",
        "    tn, fp, fn, tp = confusion_matrix(y, (y_probas_train > 0.5).astype(int)).ravel()\n",
        "    sensitivity = tp / (tp + fn)\n",
        "    specificity = tn / (tn + fp)\n",
        "\n",
        "    # Calculate Accuracy\n",
        "    accuracy_train = accuracy_score(y, (y_probas_train > 0.5).astype(int))\n",
        "\n",
        "    train_results[model_name] = {\n",
        "        'AUC': auc_train,\n",
        "        'MCC': mcc,\n",
        "        'Sensitivity': sensitivity,\n",
        "        'Specificity': specificity,\n",
        "        'Accuracy': accuracy_train\n",
        "    }\n",
        "\n",
        "    # Plot ROC curve for training set\n",
        "    axs[0].plot(fpr_train, tpr_train, label=f'{model_name} (AUC = {auc_train:.2f}')\n",
        "    axs[0].set_xlabel('False Positive Rate')\n",
        "    axs[0].set_ylabel('True Positive Rate')\n",
        "    axs[0].set_title('ROC Curve - Ten-fold cross-validation')\n",
        "    axs[0].legend()\n",
        "\n",
        "    # Predict on the test set\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Calculate accuracy for the test set\n",
        "    accuracy_test = accuracy_score(y_test, y_pred)\n",
        "    test_results[model_name] = {'Test Accuracy': accuracy_test}\n",
        "\n",
        "    # Predict on the test set\n",
        "    y_probas_test = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    # Calculate AUC for the test set\n",
        "    fpr_test, tpr_test, _ = roc_curve(y_test, y_probas_test)\n",
        "    auc_test = roc_auc_score(y_test, y_probas_test)\n",
        "\n",
        "    # Calculate Matthews Correlation Coefficient\n",
        "    mcc = matthews_corrcoef(y_test, (y_probas_test > 0.5).astype(int))\n",
        "\n",
        "    # Calculate Sensitivity and Specificity\n",
        "    tn, fp, fn, tp = confusion_matrix(y_test, (y_probas_test > 0.5).astype(int)).ravel()\n",
        "    sensitivity = tp / (tp + fn)\n",
        "\n",
        "\n",
        "    # Plot ROC curve for test set\n",
        "    axs[1].plot(fpr_test, tpr_test, label=f'{model_name} (AUC = {auc_test:.2f}')\n",
        "    axs[1].set_xlabel('False Positive Rate')\n",
        "    axs[1].set_ylabel('True Positive Rate')\n",
        "    axs[1].set_title('ROC Curve - Test Set')\n",
        "    axs[1].legend()\n",
        "\n",
        "    test_results[model_name]['AUC'] = auc_test\n",
        "    test_results[model_name]['MCC'] = mcc\n",
        "    test_results[model_name]['Sensitivity'] = sensitivity\n",
        "    test_results[model_name]['Specificity'] = tn / (tn + fp)\n",
        "\n",
        "    # Print results\n",
        "    print(f'{model_name} Metrics of Training Set:')\n",
        "    for metric, value in train_results[model_name].items():\n",
        "        print(f'{metric}: {value:.4f}')\n",
        "\n",
        "    print(f'{model_name} Metrics of Test Set:')\n",
        "    for metric, value in test_results[model_name].items():\n",
        "        print(f'{metric}: {value:.4f}')\n",
        "\n",
        "    print('-' * 30)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YzF3KH_XqKE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import matthews_corrcoef, confusion_matrix, roc_curve, roc_auc_score, accuracy_score\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Create a dictionary of models\n",
        "models = {\n",
        "    'Random Forest': RandomForestClassifier(n_estimators=300,random_state=42,max_depth=10),\n",
        "    'LightGBM': lgb.LGBMClassifier(force_col_wise=True, n_estimators=100, max_depth=10, num_leaves=50, learning_rate=0.2),\n",
        "    'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=5),\n",
        "    'Decision Tree': DecisionTreeClassifier(criterion='entropy', max_depth=10, min_samples_split=10, min_samples_leaf=2, random_state=42),\n",
        "    'XGBoost': xgb.XGBClassifier(learning_rate=0.1, max_depth=3, reg_lambda=0.5, n_estimators=100)\n",
        "}\n",
        "\n",
        "# Create subplots\n",
        "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# Initialize the result dictionaries\n",
        "train_results = {}\n",
        "test_results = {}\n",
        "\n",
        "# Loop through each model\n",
        "for model_name, model in models.items():\n",
        "    # Fit the model\n",
        "    model.fit(X, y)\n",
        "\n",
        "    # Perform cross-validation and get predicted probabilities for training set\n",
        "    y_probas_train = cross_val_predict(model, X, y, cv=10, method=\"predict_proba\")[:, 1]\n",
        "\n",
        "    # Calculate AUC for training set\n",
        "    fpr_train, tpr_train, _ = roc_curve(y, y_probas_train)\n",
        "    auc_train = roc_auc_score(y, y_probas_train)\n",
        "\n",
        "    # Calculate Matthews Correlation Coefficient\n",
        "    mcc = matthews_corrcoef(y, (y_probas_train > 0.5).astype(int))\n",
        "\n",
        "    # Calculate Sensitivity and Specificity\n",
        "    tn, fp, fn, tp = confusion_matrix(y, (y_probas_train > 0.5).astype(int)).ravel()\n",
        "    sensitivity = tp / (tp + fn)\n",
        "    specificity = tn / (tn + fp)\n",
        "\n",
        "    # Calculate Accuracy\n",
        "    accuracy_train = accuracy_score(y, (y_probas_train > 0.5).astype(int))\n",
        "\n",
        "    train_results[model_name] = {\n",
        "        'AUC': auc_train,\n",
        "        'MCC': mcc,\n",
        "        'Sensitivity': sensitivity,\n",
        "        'Specificity': specificity,\n",
        "        'Accuracy': accuracy_train\n",
        "    }\n",
        "\n",
        "    # Plot ROC curve for training set\n",
        "    axs[0].plot(fpr_train, tpr_train, label=f'{model_name} (AUC = {auc_train:.2f}')\n",
        "    axs[0].set_xlabel('False Positive Rate')\n",
        "    axs[0].set_ylabel('True Positive Rate')\n",
        "    axs[0].set_title('ROC Curve - Ten-fold cross-validation')\n",
        "    axs[0].legend()\n",
        "\n",
        "    # Predict on the test set\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Calculate accuracy for the test set\n",
        "    accuracy_test = accuracy_score(y_test, y_pred)\n",
        "    test_results[model_name] = {'Test Accuracy': accuracy_test}\n",
        "\n",
        "    # Predict on the test set\n",
        "    y_probas_test = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    # Calculate AUC for the test set\n",
        "    fpr_test, tpr_test, _ = roc_curve(y_test, y_probas_test)\n",
        "    auc_test = roc_auc_score(y_test, y_probas_test)\n",
        "\n",
        "    # Calculate Matthews Correlation Coefficient\n",
        "    mcc = matthews_corrcoef(y_test, (y_probas_test > 0.5).astype(int))\n",
        "\n",
        "    # Calculate Sensitivity and Specificity\n",
        "    tn, fp, fn, tp = confusion_matrix(y_test, (y_probas_test > 0.5).astype(int)).ravel()\n",
        "    sensitivity = tp / (tp + fn)"
      ],
      "metadata": {
        "id": "u6sb4Fg9pj3K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e7zL8E7xp9Ml"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}